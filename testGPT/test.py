# from langchain_community.llms import Ollama
# from langchain_community.callbacks.manager import get_openai_callback

# model = Ollama(model="gemma2:2b")
# query = "What is the capital of France?"

# with get_openai_callback() as cb:
#     response = model.invoke(query)
#     print(type(response))
#     print(response)
#     print(cb)

# custom_search_api = AIzaSyBWuWAqL6WcZTm2Z0hL1OKXWyIaqy4TAfM